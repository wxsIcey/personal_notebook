# process_reqs源码级解析

文章基于vllm v0.8.4 vllm-ascend v0.8.4rc2，对模型执行处理请求阶段进行源码分析，即从SchedulerOutput开始，讲解处理请求阶段，对应代码为[_process_reqs()](https://github.com/vllm-project/vllm-ascend/blob/v0.8.4rc2/vllm_ascend/worker/model_runner_v1.py#L484)

process_reqs要考虑三种情况：

- 所有的请求都在prefill阶段
- 存在请求在decode阶段
- 所有请求都在decode阶段（比较简单，暂不进行分析）
  
假定`block_size=2，max_model_len=12，max_num_blocks_per_req=12/2=6, max_token_scheduled=10, max_request=4`

## 所有的请求都在prefill阶段

### 计算token所在逻辑块索引

经过Scheduler后，假设目前有3个请求被调度，如下所示：

- 请求0：处于全填充阶段，token数量为3
- 请求1：处于全填充阶段，token数量为2
- 请求2：处于半填充阶段，token数量为8（由于最多可以处理10个token，则该请求被调度的token数为5）

逻辑块索引的计算方式如下：

`block_table_indices = (req_indices * max_num_blocks_per_req + positions_np // self.block_size)`

- `req_indices`指请求编号，形状为[num_tokens],表示每个token属于哪个请求，即[0, 0, 0, 1, 1, 2, 2, 2, 2, 2]
- `positions_np`指每个token在所属请求中的绝对位置，即[0, 1, 2, 0, 1, 0, 1, 2, 3, 4]
- `block_table_indices`即为[0, 0, 1, 6, 6, 12, 12, 13, 13, 14],表示**当前token所在的逻辑块索引**
  
### 构建 inputs attention metadata

从源码中可以得出AscendMetadata类需要以下参数：

- block_tables: 每个序列的物理块地址表。它是一个张量，其中每一行对应一个序列，存储该序列使用的物理块列表
- query_lens: 当前需要计算的 token 数量（例如，预填充阶段的输入 token 数量或解码阶段的新 token 数量
- seq_lens: 每个序列的总长度（sequence length），即已计算的 token 数量加上新增的 token 数量
- max_query_len: 所有查询的最大长度
- slot_mapping: 输入 token 将被存储到的物理位置的索引
- attn_mask: 可选的注意力掩码张量，用于屏蔽某些位置的注意力计算

根据以上内容，可知：

- block_tables: 下面计算
- query_lens: [3, 2, 5]
- seq_lens: [3, 2, 5]
- max_query_len: 5
- slot_mapping: 下面计算
- attn_mask: 对于所有请求的预填充，我们只需创建一个掩码矩阵，以便在不同的请求之间重复使用，形状为 5 * 5

当前的Block Table如下，注意Block0是不能被使用的，Block Table形状为(max_num_request, max_model_len / block_size)，如下表所示，T_0_0和T_0_1填充入Block1, T_0_2填充入Block2（注意不同请求的token肯定会填充在不同的Block）， T_1_0 和 T_1_1填充在Block3，依次类推

```
| 1  | 2  | 0  | 0  | 0  | 0  |
| 3  | 0  | 0  | 0  | 0  | 0  |
| 4  | 5  | 6  | 0  | 0  | 0  |
| 0  | 0  | 0  | 0  | 0  | 0  |
......
......
......
```

- device_block_numbers = block_table[block_table_indices] = [1, 1, 2, 3, 3, 4, 4, 5, 5, 6]
- block_offsets = positions_np % block_size = [0, 1, 0, 0, 1, 0, 1, 0, 1, 0]
- slot mapping = device_block_number * block_size + block_offsets = [2, 3, 4, 6, 7, 8, 9, 10, 11, 12]

## 存在请求在decode阶段

### 计算token所在逻辑块索引

经过前一步所有的请求都在prefill阶段，该次请求如下所示：

- 请求0：处于解码阶段，token数量为1
- 请求1：处于解码阶段，token数量为1
- 请求2：处于填充阶段，token数量为3

之前的计算不再赘述，可以得到当前的各个参数

- `req_indices`: [0, 1, 2, 2, 2]
- `positions_np`: [3, 2, 5, 6, 7]
- `block_table_indices`: [1, 7, 14, 15, 15]

根据以上内容，可知：

- block_tables: 下面计算
- query_lens: [1, 1, 3]
- seq_lens: [4, 3, 8]
- max_query_len: 3
- slot_mapping: 下面计算
- attn_mask: 形状为5*8， 每个token都会有一个1*8的向量，共有5个被调度的token
  
### 构建inputs attention metadata

当前的Block Table：从上一步得知，Block2并没有装满，请求0生成的T_0_2会直接装入Block2，请求1生成的T_1_2则会被装入Block7，请求2新增的请求token则被装入Block7和Block8，如表所示：

```
| 1  | 2  | 0  | 0  | 0  | 0  |
| 3  | 7  | 0  | 0  | 0  | 0  |
| 4  | 5  | 6  | 8  | 0  | 0  |
| 0  | 0  | 0  | 0  | 0  | 0  |
......
......
......
```

- device_block_numbers = block_table[block_table_indices] = [2, 7, 6, 8, 8]
- block_offsets = positions_np % block_size = [1, 0, 1, 0, 1]
- slot mapping = device_block_number * block_size + block_offsets = [5, 14, 13, 16, 17]

## Note

为什么block_table_indices的计算方式不是token_indices // block_size?

假设`max_model_len=5, block_size=2, max_num_blocks_per_req=5//2=3, token_indices=[0, 1, 0, 1, 2, 3, 4, 0, 1, 2]`, 按照该计算方式得到的block_table_indices为[0, 0, 0, 0, 1, 1, 2, 0, 0, 1]，可以发现请求0和请求2的token均有映射到块0的，破坏了请求隔离性，导致块冲突。
